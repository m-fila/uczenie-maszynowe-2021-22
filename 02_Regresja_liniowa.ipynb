{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/m-fila/uczenie-maszynowe-2021-22/blob/main/02_Regresja_liniowa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0fVD-WRKhgE2"
   },
   "source": [
    "# Regresja liniowa\n",
    "Autor: Jarosław Żygierewicz, Artur Kalinowski, Mateusz Fila\n",
    "\n",
    "Importujemy ponownie powtórzone `numpy`, dodajemy moduł do tworzenia wykresów `pyplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DB6NUjsLhTLd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as py\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OE_3hFYtIDv-"
   },
   "source": [
    "# Zapoznanie z regresją liniową\n",
    "* W ramach tego ćwiczenia będziemy chcieli opisać zbiór danych modelem liniowym.\n",
    "* Zbiór danych stworzymy sami w sposób sztuczny, ale w typowych problemach zebranie i obróbka danych stanowi znaczącą część pracy.\n",
    "* Nasz liniowy model ma postać: $y = \\theta_0 + \\theta_1 x$\n",
    "* Dane wytworzymy dla konkretnych $\\theta_0$ i $\\theta_1$, a następnie zaimplementujemy regresję liniową, aby znaleźć jak najlepsze przybliżenie dla tych parametrów.\n",
    "* `(X,Y)` to ciąg uczący"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8PHcEKITkFAc"
   },
   "source": [
    "## Produkcja danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnbVmOFqIDv_"
   },
   "source": [
    "Dane wytworzymy według liniowej zależności \n",
    "$$\n",
    "y = \\theta_0 + \\theta_1 \\cdot x\n",
    "$$\n",
    "Ustalamy parametry dla symulacji na $\\theta_0 = 5$ i $\\theta_1 = 3$. Dla wygody włóżmy oba parametry do wektora (np.array):\n",
    "$$\n",
    "\\vec{\\theta} = (\\theta_{0}, \\theta_{1})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = 5\n",
    "theta1 = 3\n",
    "theta = np.array([theta0, theta1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Użyjemy **nPoints** równoodległych punktów $x$ i dla nich wygenerujemy punkty wg. założonego modelu. Dla wygody dane załadujemy do obiektu `DataFrame`. By to zrobić musimy zmienić wektor na kolumnowy o kształcie $(-1,1)$. Użyjemy do tego użyciu funkcji `reshape()` (ta zamiana także przyda się w dalszej części ćwiczeń)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPoints = 100\n",
    "x = np.linspace(0, 10, nPoints)\n",
    "x = np.reshape(x, (-1,1))\n",
    "\n",
    "df = pd.DataFrame(data=x, columns = [\"x\"])\n",
    "df[\"y\"] = theta[0] + df[\"x\"]*theta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3l9-73PIDwD"
   },
   "source": [
    "Do danych \"czystych\" dodajmy kolumnę z danymi z szumem Gaussowskim:\n",
    "$$ y_{noise} = y + Rand(N(0,1)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x          y    y_noise\n",
      "0    0.00000   5.000000   3.432689\n",
      "1    0.10101   5.303030   3.837029\n",
      "2    0.20202   5.606061   6.401906\n",
      "3    0.30303   5.909091   5.098037\n",
      "4    0.40404   6.212121   6.339567\n",
      "..       ...        ...        ...\n",
      "95   9.59596  33.787879  33.528903\n",
      "96   9.69697  34.090909  35.094582\n",
      "97   9.79798  34.393939  33.618642\n",
      "98   9.89899  34.696970  34.595930\n",
      "99  10.00000  35.000000  33.287762\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"y\"] = theta0 + df[\"x\"]*theta1\n",
    "df[\"y_noise\"] = df[\"y\"] + np.random.randn(nPoints)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yewJ96CHIDwL"
   },
   "source": [
    "Obejrzyjmy te dane. Proszę narysować:\n",
    "<ul>\n",
    "    <li> na jednym rysunku: y vs x oraz y_noise vs x </li>\n",
    "    <li> na drugim rysunku: histogram y - y_noise\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c_r-QQtsIDwR"
   },
   "source": [
    "## Algorytm równań normalnych\n",
    "Proszę napisać funkcję ```normal_equations(x,y)``` która:\n",
    "* na wejściu przyjmuje ciąg uczący $x,y$, implementuje wzór na parametry optymalne na podstawie [równań normalnych](http://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/Wykład_1#Minimalizacja_funkcji_kosztu ). \n",
    "* funkcja powinna zwracać estymowane parametry $(\\theta_{0}^{est}, \\theta_{1}^{est})$\n",
    "* funkcja p[owinna być przetestowana na czystych danych, czli parze $(x,y)$, a potem na danych zaszumionych $(x ,y_{noise}$)\n",
    "* proszę dorysować prostą reprezentującą hipotezę do wykresu punktów ciągu uczącego.\n",
    "* dla przypomnienia: odwrotność macierzy można obliczyć w numpy funkcją: <tt>numpy.linalg.inv</tt>\n",
    "* proszę zwrócić uwagę, że konieczne jest użycie wektorów kolumnowych!\n",
    "\n",
    "**Wskazówka:** aby skorzystać ze wzorów z wykładu, macierz wejść $X$ musi zawierać nie tylko kolumnę $x$, ale także kolumnę jedynek, aby przemnożona przez wektor [$\\theta_0$ $\\theta_1$] dawała odpowiedni wektor (kolumnowy) wyjść $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prawdziwe wartości parametrów: [5 3]\n",
      "wartości estymowane za pomocą równań normalnych dla nominalnych danych: [5 3]\n"
     ]
    }
   ],
   "source": [
    "def normal_equations(x,y):\n",
    "    # YOUR CODE HERE\n",
    "    # theta = \n",
    "    return theta\n",
    "\n",
    "theta_est = normal_equations(df[\"x\"], df[\"y\"])\n",
    "\n",
    "print(\"prawdziwe wartości parametrów:\", theta.T)\n",
    "print(\"wartości estymowane za pomocą równań normalnych dla nominalnych danych:\", theta_est.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korzystając z oszacowanych parametrów prostej proszę narysować:\n",
    "* punkty dla danych zaszumionych\n",
    "* linię prostą dopasowaną do danych szasumionych\n",
    "* linię prostą dla nominalnych parametrów\n",
    "* linię prostą dopasowaną do losowego ułamka próbki, wybranego z użyciem funkcji pandas.DataFrame.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_est = normal_equations(df[\"x\"], df[\"y_noise\"])\n",
    "print(\"Wartości estymowane za pomocą równań normalnych dla zaszumionych danych:\", theta_est.T)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# y_fit = \n",
    "# y_original = \n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# axes[0].plot(\n",
    "# axes[0].plot(\n",
    "# axes[0].plot(\n",
    "axes[0].set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].legend()\n",
    "\n",
    "df_subsample = df.sample(frac=0.05)\n",
    "theta_est = normal_equations(df_subsample[\"x\"], df_subsample[\"y_noise\"])\n",
    "print(\"Wartości estymowane za pomocą równań normalnych dla zaszumionych danych: {} \\ndla podpróbki obejmującej 5% przypadków.\".format(theta_est.T))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# y_fit = \n",
    "# axes[1].plot(\n",
    "\n",
    "axes[1].set_xlabel(\"x\")\n",
    "axes[1].set_ylabel(\"y\")\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HA0EFYBIDwV"
   },
   "source": [
    "## Algorytm gradientowy stochastyczny \n",
    "\n",
    "Proszę napisać funkcję ```iterative_stochastic_gradient(x,y, theta, alpha, nIter)``` która:\n",
    "* na wejściu przyjmuje ciąg uczący w postaci obiektu pandas.DataFrame, wartości początkowe $(\\theta_{0}, \\theta_{1})$, parametr szybkości zbiegania $\\alpha$ oraz liczbę iteracji nIter\n",
    "* implementuje wzór na parametry optymalne na podstawie [równań normalnych](http://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/Wykład_1#Minimalizacja_funkcji_kosztu ). \n",
    "* funkcja powinna zwracać estymowane parametry $(\\theta_{0}^{est}, \\theta_{1}^{est})$ dla wszystkich iteracji, czyli zwracać tablicę o kształcie\n",
    " $(nIter+1, 2)$. Początkową wartość $(\\theta_{0}^{est}, \\theta_{1}^{est})$ także należy dołączyc, stąd nIter+1 elementów\n",
    "* funkcja powinna być przetestowana na czystych danych, czyli parze $(x,y)$ z poczatkową wartością $(\\theta_{0}, \\theta_{1})$$(\\theta_{0}, \\theta_{1})$ równą nominalnej, oraz różnej od nominalnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartości estymowane z użyciem nominalnej wartości początkowej parametrów theta: 3\n",
      "Wartości estymowane z użyciem różnej od nominalnej wartości początkowej parametrów theta: 3\n",
      "CPU times: user 1.63 ms, sys: 181 µs, total: 1.81 ms\n",
      "Wall time: 1.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def iterative_stochastic_gradient(x, y, init_theta, alpha, nIter):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # theta_est = \n",
    "    return theta_est   \n",
    "        \n",
    "          \n",
    "theta_est = iterative_stochastic_gradient(df[\"x\"], df[\"y\"], theta, 0.01, 1)    \n",
    "print(\"Wartości estymowane z użyciem nominalnej wartości początkowej parametrów theta:\",theta_est[-1])\n",
    "\n",
    "theta_est = iterative_stochastic_gradient(df[\"x\"], df[\"y\"], theta+2, 0.01, 500)    \n",
    "print(\"Wartości estymowane z użyciem różnej od nominalnej wartości początkowej parametrów theta:\",theta_est[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę narysować następujące rysunki:\n",
    "* dane, oraz krzywe regressji dla wszyskich iteracji na jednym rysunku\n",
    "* wartości parametrów $\\theta_{0}$ i $\\theta_{1}$ w funkcji numeru iteracji dla $\\alpha$ = 0.1, 0.05 oraz 0.01 oraz 10 iteracji\n",
    "* wartości parametrów $\\theta_{0}$ i $\\theta_{1}$ w funkcji numeru iteracji dla $\\alpha$ = 0.01 dla 100 iteracji\n",
    "\n",
    "W każdym przypadku jako wartości początkowe proszę przyjąć ($\\theta_{0}$, $\\theta_{1}$) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4, figsize=(20,5))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# theta_est = \n",
    "# x = \n",
    "# y_fit = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "# axes[0].plot(\n",
    "# axes[0].plot(\n",
    "# axes[0].plot(\n",
    "# axes[0].plot(\n",
    "axes[0].set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].legend()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# theta_alpha_01 = \n",
    "# theta_alpha_005 = \n",
    "# theta_alpha_001 = \n",
    "# theta_alpha = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "# axes[1].plot(\n",
    "# axes[1].plot(\n",
    "# axes[1].plot(\n",
    "axes[1].set_xlabel(\"Iteration number\")\n",
    "axes[1].set_ylabel(r'$\\theta_{0}$')\n",
    "axes[1].legend()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# axes[2].plot(\n",
    "# axes[2].plot(\n",
    "# axes[2].plot(\n",
    "axes[2].set_xlabel(\"Iteration number\")\n",
    "axes[2].set_ylabel(r'$\\theta_{1}$')\n",
    "axes[2].legend()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# axes[3].plot(\n",
    "# axes[3].plot(\n",
    "# axes[3].plot(\n",
    "# axes[3].plot(\n",
    "axes[3].set_xlabel(\"Iteration number\")\n",
    "axes[3].set_ylabel(r'$\\theta_{i}$')\n",
    "axes[3].legend()\n",
    "\n",
    "print(\"Finalna wartość parametrów dla alpha=0.1, nIter = 10: \\t\\t\",theta_alpha_01[-1])\n",
    "print(\"Finalna wartość parametrów dla alpha=0.05, nIter = 10: \\t\\t\",theta_alpha_005[-1])\n",
    "print(\"Finalna wartość parametrów dla alpha=0.001, nIter = 10: \\t\",theta_alpha_001[-1])\n",
    "print(\"Finalna wartość parametrów dla alpha=0.001, nIter = 100: \\t\",theta_alpha[-1])\n",
    "print(\"Oryginalna wartośc parametrów: \\t\\t\\t\\t\",theta)\n",
    "\n",
    "plt.subplots_adjust(bottom=0.15, left=0.05, right=0.95, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorytm gradientowy zbiorczy\n",
    "\n",
    "Proszę napisać funkcję ```iterative_batch_gradient(x,y, theta, alpha, nIter)``` która:\n",
    "* na wejściu przyjmuje ciąg uczący w postaci obiektu pandas.DataFrame, wartości początkowe $(\\theta_{0}, \\theta_{1})$, parametr szybkości zbiegania $\\alpha$ oraz liczbę iteracji nIter\n",
    "* implementuje wzór na parametry optymalne na podstawie [równań normalnych](http://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/Wykład_1#Minimalizacja_funkcji_kosztu ). \n",
    "* funkcja powinna zwracać estymowane parametry $(\\theta_{0}^{est}, \\theta_{1}^{est})$ dla wszystkich iteracji, czyli zwracać tablicę o kształcie\n",
    " $(nIter+1, 2)$. Początkową wartość $(\\theta_{0}^{est}, \\theta_{1}^{est})$ także należy dołączyc, stąd nIter+1 elementów\n",
    "* funkcja powinna być przetestowana na czystych danych, czyli parze $(x,y)$ z poczatkową wartością $(\\theta_{0}, \\theta_{1})$ równą nominalnej, oraz różnej od nominalnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartości estymowane z użyciem nominalnej wartości początkowej parametrów theta: [5. 3.]\n",
      "Wartości estymowane z użyciem różnej od nominalnej wartości początkowej parametrów theta: [5.88       3.22996633]\n",
      "CPU times: user 23.5 ms, sys: 3.61 ms, total: 27.2 ms\n",
      "Wall time: 26.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def iterative_batch_gradient(x, y, init_theta, alpha, nIter):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # theta_est = \n",
    "    return theta_est   \n",
    "        \n",
    "theta_est = iterative_batch_gradient(df[\"x\"], df[\"y\"], init_theta=theta, alpha=0.01, nIter=1)    \n",
    "print(\"Wartości estymowane z użyciem nominalnej wartości początkowej parametrów theta:\",theta_est[-1])\n",
    "\n",
    "theta_est = iterative_batch_gradient(df[\"x\"], df[\"y\"], init_theta=theta+1, alpha=0.01, nIter=1)    \n",
    "print(\"Wartości estymowane z użyciem różnej od nominalnej wartości początkowej parametrów theta:\",theta_est[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proszę narysować następujące rysunki:\n",
    "* dane, oraz krzywe regressji dla wszyskich iteracji na jednym rysunku\n",
    "* wartości parametrów $\\theta_{0}$ i $\\theta_{1}$ w funkcji numeru iteracji dla $\\alpha$ = 0.1, 0.05 oraz 0.01 oraz 10 iteracji\n",
    "* wartości parametrów $\\theta_{0}$ i $\\theta_{1}$ w funkcji numeru iteracji dla $\\alpha$ = 0.01 dla 100 iteracji\n",
    "\n",
    "W każdym przypadku jako wartości początkowe proszę przyjąć ($\\theta_{0}$, $\\theta_{1}$) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4, figsize=(20,5))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# theta_est = \n",
    "# x = \n",
    "# y_fit = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "# axes[0].plot(\n",
    "# axes[0].plot(\n",
    "# axes[0].plot(\n",
    "# axes[0].plot(\n",
    "axes[0].set_xlabel(\"x\")\n",
    "axes[0].set_ylabel(\"y\")\n",
    "axes[0].legend()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# theta_alpha_01 = \n",
    "# theta_alpha_005 = \n",
    "# theta_alpha_001 = \n",
    "# theta_alpha = \n",
    "\n",
    "# YOUR CODE HERE\n",
    "# axes[1].plot(\n",
    "# axes[1].plot(\n",
    "# axes[1].plot(\n",
    "axes[1].set_xlabel(\"Iteration number\")\n",
    "axes[1].set_ylabel(r'$\\theta_{0}$')\n",
    "axes[1].legend()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# axes[2].plot(\n",
    "# axes[2].plot(\n",
    "# axes[2].plot(\n",
    "axes[2].set_xlabel(\"Iteration number\")\n",
    "axes[2].set_ylabel(r'$\\theta_{1}$')\n",
    "axes[2].legend()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# axes[3].plot(\n",
    "# axes[3].plot(\n",
    "# axes[3].plot(\n",
    "# axes[3].plot(\n",
    "axes[3].set_xlabel(\"Iteration number\")\n",
    "axes[3].set_ylabel(r'$\\theta_{i}$')\n",
    "axes[3].legend()\n",
    "\n",
    "print(\"Finalna wartość parametrów dla alpha=0.1, nIter = 10: \\t\\t\",theta_alpha_01[-1])\n",
    "print(\"Finalna wartość parametrów dla alpha=0.05, nIter = 10: \\t\\t\",theta_alpha_005[-1])\n",
    "print(\"Finalna wartość parametrów dla alpha=0.001, nIter = 10: \\t\",theta_alpha_001[-1])\n",
    "print(\"Finalna wartość parametrów dla alpha=0.001, nIter = 100: \\t\",theta_alpha[-1])\n",
    "print(\"Oryginalna wartośc parametrów: \\t\\t\\t\\t\",theta)\n",
    "\n",
    "plt.subplots_adjust(bottom=0.15, left=0.05, right=0.95, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKgTHdG9IDwe"
   },
   "source": [
    "## Porównanie algorytmów\n",
    "Proszę sprawdzić czy algorytmy optymalizacyjne działają poprawnie dla danych gdzie błąd podlega innym rozkładom prawdopodobieństwa niż normalny:\n",
    "\n",
    "* dla rozkładu jednorodnego w zakrtesie [-1,1[\n",
    "* dla rozkłatu t-Studenta o trzech stopniach swobody\n",
    "\n",
    "Dla wszystkch trzech rozkładów proszę narysować wartości parametrów $\\theta_{0}$ i $\\theta_{1}$ w funkcji numeru iteracji dla $\\alpha$ = 0.01 i 100 iteracji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           x          y    y_noise  y_flat_noise  y_tStudent_noise\n",
      "0    0.00000   5.000000   5.816979      4.723023          6.126249\n",
      "1    0.10101   5.303030   5.340698      4.643993         -2.343500\n",
      "2    0.20202   5.606061   6.462301      4.805613          5.012846\n",
      "3    0.30303   5.909091   5.322659      6.155243          5.692222\n",
      "4    0.40404   6.212121   5.301430      6.513775          7.180299\n",
      "..       ...        ...        ...           ...               ...\n",
      "95   9.59596  33.787879  32.705299     33.530013         34.683707\n",
      "96   9.69697  34.090909  33.273414     33.767999         31.609354\n",
      "97   9.79798  34.393939  35.062783     33.432946         33.858484\n",
      "98   9.89899  34.696970  33.137135     33.834136         34.457895\n",
      "99  10.00000  35.000000  33.187367     34.899603         35.549503\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"y_flat_noise\"] = df[\"y\"] + -1 + 2*np.random.random(nPoints)\n",
    "df[\"y_tStudent_noise\"] = df[\"y\"] + np.random.standard_t(df=3, size=nPoints)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize=(10,5))\n",
    "\n",
    "axes[0].hist(df[\"y\"] - df[\"y_noise\"])\n",
    "axes[1].hist(df[\"y\"] - df[\"y_flat_noise\"])\n",
    "axes[2].hist(df[\"y\"] - df[\"y_tStudent_noise\"])\n",
    "\n",
    "axes[0].set_title(\"Gaussian noise\")\n",
    "axes[0].set_xlabel(r'$y - \\hat{y}$')\n",
    "axes[0].set_ylabel(\"Number of events\")\n",
    "\n",
    "axes[1].set_title(\"Flat [-1,1] noise\")\n",
    "axes[1].set_xlabel(r'$y - \\hat{y}$')\n",
    "axes[1].set_ylabel(\"Number of events\")\n",
    "\n",
    "axes[2].set_title(\"t-Student, ndof=3 noise\")\n",
    "axes[2].set_xlabel(r'$y - \\hat{y}$')\n",
    "axes[2].set_ylabel(\"Number of events\")\n",
    "\n",
    "plt.subplots_adjust(bottom=0.15, left=0.05, right=0.95, wspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "nIter = 1000\n",
    "\n",
    "# YOUR CODE HERE \n",
    "# theta_gaussian_noise\n",
    "# theta_flat_noise\n",
    "# theta_tStudent_noise\n",
    "\n",
    "# YOUR CODE HERE \n",
    "# axes[0].plot(\n",
    "# axes[0].plot(\n",
    "# # axes[0].plot(   \n",
    "axes[0].plot(np.full(nIter,theta[0]),  \"--b\",linewidth=3.0)\n",
    "axes[0].set_xlabel(\"Iteration number\")\n",
    "axes[0].set_ylabel(r'$\\theta_{0}$')\n",
    "axes[0].legend()\n",
    "\n",
    "# YOUR CODE HERE \n",
    "# axes[1].plot(\n",
    "# axes[1].plot(\n",
    "# # axes[1].plot(   axes[1].plot(np.full(nIter,theta[1]), \"--b\",  linewidth=3.0)\n",
    "axes[1].set_xlabel(\"Iteration number\")\n",
    "axes[1].set_ylabel(r'$\\theta_{1}$')\n",
    "axes[1].legend()\n",
    "\n",
    "print(\"Finalna wartość parametrów dla szumu gaussowskiego, nIter = 100: \\t\",theta_gaussian_noise[-1])\n",
    "print(\"Finalna wartość parametrów dla szumu płaskiego, nIter = 100: \\t\\t\",theta_flat_noise[-1])\n",
    "print(\"Finalna wartość parametrów dla szumu tStudenta, nIter = 100: \\t\\t\",theta_tStudent_noise[-1])\n",
    "print(\"Oryginalna wartośc parametrów: \\t\\t\\t\\t\\t\",theta)\n",
    "\n",
    "plt.subplots_adjust(bottom=0.15, left=0.05, right=0.95, wspace=0.3)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01b_Regresja_liniowa.ipynb",
   "provenance": [
    {
     "file_id": "0BzwQ_Lscn8yDWnZVeHU1MjluWFU",
     "timestamp": 1546856440599
    }
   ]
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
