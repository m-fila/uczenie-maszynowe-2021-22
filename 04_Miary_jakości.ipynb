{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/m-fila/uczenie-maszynowe-2021-22/blob/main/04_Miary_jakości.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autor: Jarosław Żygierewicz\n",
    "\n",
    "# Przygotowanie środowiska programistycznego.\n",
    "W tym ćwiczeniu skorzystamy z modułu sklearn [scikit-learn](https://scikit-learn.org/stable/auto_examples/index.html) przeznaczonego do uczenia maszynowego. Zawiera wiele zoptymalizowanych i przydatnych funkcji i algorytmów. Alternatywnymi frameworkami są np. [PyTorch](https://pytorch.org/tutorials/), [Tensorflow](https://www.tensorflow.org/tutorials), [Keras](https://keras.io/examples/), [Caffe2](https://caffe2.ai/docs/tutorials), chociaż z obserwacji środowiska wynika, że dominują raczej PyTorch i Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1725,
     "status": "ok",
     "timestamp": 1605186097417,
     "user": {
      "displayName": "Anna Dawid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUQAwZ7wyayL4BbiM0n_EANCgBjSdZ9H14lgcCFEE=s64",
      "userId": "02862484648310443813"
     },
     "user_tz": -60
    },
    "id": "ZEDtJYrxqvsg",
    "outputId": "8e6705dc-8c21-442a-88f0-ad4dad0919c0"
   },
   "outputs": [],
   "source": [
    "import sklearn\r\n",
    "print('Zainstalowana wersja scikit-learn: {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wFBQnvOqvsr"
   },
   "source": [
    "Na stronie przedmiotu znajduje się instrukcja konfiguracji środowiska w przypadku pracy lokalnej, a nie w colabie. Może (nie musi) być przydatna dla osób pracujących na własnych laptopach:\n",
    "\n",
    "https://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/konfiguracja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zanim przejdziemy do właściwych zadań zaimportujmy potrzebne moduły:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import diag, interp\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YibBq2d4qvs0"
   },
   "source": [
    "# Ćwiczenie: Walidacja krzyżowa\n",
    "Już na ostatnich ćwiczeniach przerobiliśmy walidację krzyżową (ang. cross validation). Teraz przyjrzymy się jej bliżej i sprawdźmy efekt wspomniany na wykładzie, czyli efekt częstości występowania.\n",
    "\n",
    "* W tym ćwiczeniu przyjrzymy się jak miary jakości klasyfikatora zależą od proporcji klas w zbiorze uczącym i od rozmiaru zbioru uczącego\n",
    "* Klasyfikatorem będzie nadal regresja logistyczna, ale tym razem zamiast korzystać z własnej implementacji, skorzystamy z gotowej wersji bibliotecznej z modułu [scikit-learn] (http://scikit-learn.org/stable/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GiQUZ_Cqvs1"
   },
   "source": [
    "## Produkcja danych\n",
    "\n",
    "Nasze przykłady będą należały do dwu klas: **0** lub **1**. Wartości zmiennych wejściowych $(x, y)$ dla danej klasy są dane dwuwymiarowym rozkładem Gaussa:\n",
    "\n",
    "$$\n",
    "p_{class~1}(x,y) = N(\\mu_{class~1, x}, \\mu_{class~1, y}, covariance)\n",
    "$$\n",
    "\n",
    "Proszę uzupełnić kod funkcji ```generate_class_points(nPoints, means, covariances, class)``` która zwraca macierz $(nPoints, 3)$ zawierającą położenia punktów danej klasy, oraz jej numer: (x,y,class)\n",
    "\n",
    "\n",
    "* funkcja na wejściu przyjmuje liczbę przykładów do generacji $nPoints$, macierze $means$ i $covariance$ zawierające średnie i kowariancię dla danej klasy:\n",
    "\n",
    "$$\n",
    "means = [\\mu_{x}, \\mu_{y}]\n",
    "$$\n",
    "\n",
    "$$\n",
    "covariance = \n",
    "\\begin{bmatrix}\n",
    "    \\sigma^{2}_{x} & \\sigma_{xy} \\\\\n",
    "    \\sigma_{xy} & \\sigma^{2}_{y}\n",
    "\\end{bmatrix}   \n",
    "$$\n",
    "\n",
    "* liczbę kodującą numer klasy : $class$, w naszym przypadku ***0** lub **1**\n",
    " \n",
    " \n",
    "Korzystając z funkcji  ```generate_class_points(nPoints, means, covariances)``` prosze wygenenerować po 10000 punktów dla dwu klas, dla których parametry rozkładów Gaussa są następujące:\n",
    "\n",
    "```\n",
    "means_class_1 = np.array([-1,0.5]) \n",
    "covariance_class_1 = np.diag([3,3]) \n",
    "\n",
    "means_class_2 = np.array([1.2,4]) \n",
    "covariance_class_2 = np.diag([4, 1.7]) \n",
    "```\n",
    "\n",
    "Dane proszę załadować do obiektów pandas DataFrame dla każdej z klas, a następnie je połączyć korzystając z funkcji ```pandas.concatenate()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_data(nPoints, means, covariances, label):\n",
    "    #Generacja własności - w naszym wypadku wartości (x,y) dla danej klasy\n",
    "    features = np.random.multivariate_normal(means,covariances,nPoints)\n",
    "    #Generacja macierzy z etykietami - tutaj numerem klasy\n",
    "    labels = np.full((nPoints,1), label)\n",
    "    #Połączenie macierzy dla własności i etykiet w jedną macierz\n",
    "    class_data = np.concatenate((features, labels), axis=1)\n",
    "    return class_data\n",
    "    \n",
    "nPoints = 10000    \n",
    "    \n",
    "#Defincja parametrów rozkładu Gaussa dla klasy \"0\"    \n",
    "means_class_1 = ...\n",
    "covariance_class_1 = ...\n",
    "\n",
    "#Definicja parametrów rozkładu Gaussa dla klasy \"1\"\n",
    "means_class_2 = ...\n",
    "covariance_class_2 = ...\n",
    "\n",
    "#Generacja danych dla klas \"0\" i \"1\"\n",
    "class_0_data = ...\n",
    "class_1_data = ...\n",
    "\n",
    "#Sprawdzenie czy wygenrowane dane mają poprawny kształt\n",
    "print(...)\n",
    "print(...)\n",
    "\n",
    "#Utworzenie obiektu DataFrame dla klas \"0\" i \"1\"\n",
    "df_class_0 = pd.DataFrame(...)\n",
    "df_class_1 = pd.DataFrame(...)\n",
    "\n",
    "#Utworzenie obiektu DataFrame dla odu klas lącznie\n",
    "df = pd.concat([df_class_0, df_class_1], ignore_index=True)\n",
    "\n",
    "#Wypisanie zawartości obiektu DataFrame dla odu klas lącznie\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza wizualna danych. \n",
    "\n",
    "Pierwszy krok przy analizie danych z użyciem dowolnego algorytmu to ich inspekcja. Korzystając z metod klasy DataFrame proszę:\n",
    "* narysować rozkłady wszystkich zmiennych wejściowych oddzielnie dla klas 0 i 1\n",
    "* narysować wykres korelacji między zmiennymi wejściowymi dla klas 0 i 1 na jednym rysunku\n",
    "\n",
    "**Wskazówka**: proszę użyć parametru \"hue\" funkcji sns.jointplot()\n",
    "\n",
    "Oglądając rysunki proszę sprawdzić jakościowo czy:\n",
    "* czy średnie wartości $x$ i $y$ są zgodne z założeniami? \n",
    "* czy krotnośc klas jest zgodna z założeniami?\n",
    "* czy rozkłady dwuwymiarowe są zgodne z założeniem diagonalnej macierzy kowiariancji? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogramy rozkładów dla klasy \"0\"\n",
    "df_class_0...\n",
    "\n",
    "#Histogramy rozkładów dla klasy \"1\"\n",
    "df_class_1....\n",
    "\n",
    "#Dwuwymiarowy rozkład y vs x dla klasy \"0\" i 1\"\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWmqK-c4qvtB"
   },
   "source": [
    "# Analiza dla klas równolicznych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieaSg8JlqvtD"
   },
   "source": [
    "* podziel pełne dane na podzbiory uczący (80% danych) i terningowy (20% danych). Wykonując podział zwróć uwagę na randomizację danych.\n",
    "* narysuj dwuwymiarowe rozkłądy dla zbiorów uczącego i treningowego i sprawdź wizulanie czy są różne. \n",
    "\n",
    "**Wskazówka:** do podziałów zbioru proszę użyć funkcji [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) podając obiekt DataFrame jako argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2725,
     "status": "ok",
     "timestamp": 1605186098433,
     "user": {
      "displayName": "Anna Dawid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUQAwZ7wyayL4BbiM0n_EANCgBjSdZ9H14lgcCFEE=s64",
      "userId": "02862484648310443813"
     },
     "user_tz": -60
    },
    "id": "EHbXlRRlqvtE"
   },
   "outputs": [],
   "source": [
    "#Podział danych na zbiory uczący i testowy\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "#Dwuwymiarowy rozkład y vs x dla klasy \"0\" i 1\" dla zbioru uczącego\n",
    "...\n",
    "\n",
    "#Dwuwymiarowy rozkład y vs x dla klasy \"0\" i 1\" dla zbioru testowego\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTMtVm5-qvtK"
   },
   "source": [
    "## Trening regresji logistycznej\n",
    "\n",
    "Skorzystamy z implementacji regresji logistycznej z pakietu scikit-learn.\n",
    "Regresja logistyczna zaimplementowana jest w klasie [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). \n",
    "\n",
    "* stwórz obiekt klasy ```LogisticRegression()```\n",
    "* użyj tego obiektu by wytrenować model. W tym miejscu wykonają się kroki odpowiadające procedurze minimalizacji znajdującej parametry $\\theta$ z zajęciach o regresji logistycznej\n",
    "* przeprowadź predykcję na zbiorze testowym\n",
    "\n",
    "**Wskazówka** domyślną funkcją minimalizacji jest 'lbfgs', ale warto ją podać explicite by uniknąć uciążliwego ostrzeżenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2716,
     "status": "ok",
     "timestamp": 1605186098434,
     "user": {
      "displayName": "Anna Dawid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgUQAwZ7wyayL4BbiM0n_EANCgBjSdZ9H14lgcCFEE=s64",
      "userId": "02862484648310443813"
     },
     "user_tz": -60
    },
    "id": "rTYUHUEKqvtL"
   },
   "outputs": [],
   "source": [
    "#Definicja modelu - obiektu klasy LogisticRegression\n",
    "model = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "#Przeprowadzenie minmalizacji lub dopasowania parametrów modelu (ang. fit)\n",
    "model.fit(...)\n",
    "\n",
    "#Przeprowadzenie predykcji (ang. predict)\n",
    "y_pred = model.predict(...)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKSvOoqXqvtU"
   },
   "source": [
    "Oblicz macierz pomyłek (ang. confusion matrix)\n",
    "\n",
    "* skorzystaj z funkcji ```metrics.confusion_matrix``` by wypisać wartości macierzy\n",
    "* skorzystaj z funkcji ``` metrics.plot_confusion_matrix``` by narysować macierz pomyłek\n",
    "* skorzystaj z funkcji ``` metrics.plot_confusion_matrix``` by narysować macierz pomyłek z wartościami znormalizowanymi względem liczby przykładów w prawdziwych klasach\n",
    "\n",
    "**Pytanie**: jaką iterpretację mają elementy macierzy po normalizacji?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wypisanie macierzy pomyłek w postaci tekstowej\n",
    "print(metrics.confusion_matrix(df_test[\"label\"], y_pred))\n",
    "\n",
    "#Narysowanie macierzy pomyłek. \n",
    "metrics.plot_confusion_matrix(...);  \n",
    "\n",
    "#Narysowanie macierzy pomyłek z normalizacją względem liczny przykładów w prawdziwych przykładów.\n",
    "metrics.plot_confusion_matrix(...);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PATG0geqvtX"
   },
   "source": [
    "Zbadajmy wartości różnych miar jakości:\n",
    "\n",
    "* **precyzja pozytywna (positive predictive value (PPV), precision):**\n",
    "\n",
    "$\\qquad$ $PPV = \\frac{TP}{P'}=\\frac{TP}{ TP + FP}$\n",
    "\n",
    "Ułamek przypadków oznaczonych jako klasa \"1\" który naprawdę należy do klasy \"1\". Ułamek ten jest np. odpowiedzą na pytanie\n",
    "\"Jeśli wynik testu jest pozytywny, jakie jest prawdopodobieństwo, że osoba badana jest chora?\"\n",
    "\n",
    "* **czułość: (ang. True Positive Rate, TPR, or recall):** \n",
    "\n",
    "$\\qquad$ $TPR = \\frac{TP}{ P} = \\frac{TP} { TP+FN}$\n",
    "\n",
    "Ułamek przypadków które należą do klasy \"1\" i został poprawnie oznaczony. Ułamek ten jest np. odpowiedzą na pytanie  \"Jakie jest prawdopodobieństwo, że test wykonany dla osoby chorej wykaże, że jest ona chora?\"\n",
    "\n",
    "\n",
    "* **dokładność ( accuracy (ACC)):** Prawdopodobieństwo prawidłowej klasyfikacji.\n",
    "\n",
    "$\\qquad$ $ACC = \\frac{TP + TN}{P + N}$\n",
    "\n",
    "Ułamek przypadków, niezależnie od klasy, które zostały poprawnie oznaczone. Ułamek ten jest np. odpowiedzą na pytanie  \"Jakie jest prawdopodobieństwo, że test poda poprawną odpowiedź?\" \n",
    "\n",
    "* **F1-score:** średnia harmoniczna z precyzji i czułości:\n",
    "\n",
    "$\\qquad$ $F_1= 2 \\frac{PPV  \\cdot TPR}{PPV+TPR}= \\frac{2TP}{ 2TP+FP+FN}$\n",
    "\n",
    "Miara ta daje ocenę balansu między czułością a precyzją. Miara ta nie uwzględnia wyników prawdziwie negatywnych.\n",
    "\n",
    "* **współczynnik korelacji Matthewsa ( Matthews correlation coefficient):**\n",
    "\n",
    "$\\qquad$ $\n",
    "\\text{MCC} = \\frac{ TP \\cdot TN - FP \\cdot FN } {\\sqrt{ (TP + FP) ( TP + FN ) ( TN + FP ) ( TN + FN ) } }\n",
    "$\n",
    "\n",
    "Współczynnik MMC uwzględnia wyniki zarówno prawdziwie jaki i fałszywie pozytywne i negatywne i jest na ogół uważany jako zrównoważona miara, która może być stosowana nawet wtedy, gdy klasy są bardzo różnej liczebności. \n",
    "\n",
    "MCC jest w istocie współczynnikiem korelacji pomiędzy obserwowanymi i przewidywanymi klasyfikacjami binarnymi; zwraca wartość od -1 do +1. \n",
    "\n",
    "* Współczynnik +1 odpowiada idealnej klasyfikacji, \n",
    "* 0 nie lepiej niż losowe przypisanie wyniku i \n",
    "* -1 oznacza całkowitą niezgodę między klasyfikacją  i stanem faktycznym.\n",
    " \n",
    "***\n",
    " \n",
    "Proszę uzupełnić funkcję ```calculate_metric(nIter)```, która:\n",
    "* liczy powyższe wskaźniki powtarzając podziały próbki $nIter$ razy (za każdym razem losując od nowa\n",
    "* zwraca macierz wartości miar, gdzie dla każdego wiersza mamy następujące znaczenie kolumn: $(PPV, TPR, ACC, F1, MCC)$. Macierz powinna więc mieć kształ (nIter, 5)\n",
    "\n",
    "Korzystając z funkcji ```calculate_metric(nIter)``` proszę:\n",
    "* obliczyć wartości parametrów dla 100 iteracji\n",
    "* stworzyć obiekt DataFrame zawierający kolumny \"PPV\", \"TPR\", \"ACC\", \"F1\", \"MCC\"\n",
    "* narysować rozkłady wartości miar jakości\n",
    "* narysować rozkłady dokładności jako dane podając oryginalną próbkę i próbkę stanowiącą 10% oryginalnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def calculate_metric(data, nIter):\n",
    "    model = LogisticRegression(solver = 'lbfgs') \n",
    "    result = np.array([])\n",
    "    #Pętla po kolejnych iteracjach procesu trenowania-testowania\n",
    "    for i in range(nIter):\n",
    "        #Podział próbki na części treningową i testową\n",
    "        df_train, df_test = ...\n",
    "        #znajdowanie parametrów modeli\n",
    "        ...\n",
    "        #Predykcja\n",
    "        y_pred = ... \n",
    "        y_true = df_test[\"label\"]\n",
    "        #Obliczenie wartości miar jakości\n",
    "        PPV = metrics.precision_score(y_true, y_pred)\n",
    "        TPR = metrics.recall_score(y_true, y_pred)\n",
    "        ACC = metrics.accuracy_score(y_true, y_pred)\n",
    "        F1 = metrics.f1_score(y_true, y_pred)\n",
    "        MCC = metrics.matthews_corrcoef(y_true, y_pred)\n",
    "        #Spakowanie uzyskanych licz do jednej macierzy\n",
    "        result = np.append(result, np.array([PPV, TPR, ACC, F1, MCC]), axis=0)\n",
    "        \n",
    "    result = np.reshape(result, (-1,5))    \n",
    "    return result     \n",
    "  \n",
    "#Obliczenie wartości metryk na pełnych danych    \n",
    "metrics_data = calculate_metric(df, nIter=100)\n",
    "#Przepakowanie uzyskanych liczb do obiektu DataFrame\n",
    "df_metrics = pd.DataFrame(data=metrics_data, columns = [\"PPV\", \"TPR\", \"ACC\", \"F1\", \"MCC\"])\n",
    "#Wyrysowanie histogramów dla wszystkich metryk\n",
    "df_metrics.hist(figsize=(10,15));\n",
    "\n",
    "#Obliczenie wartości metryk na 10% danych  \n",
    "...\n",
    "\n",
    "#Wyrysowanie rozkładu dokładności (ACC) dla obu zestawów danych \n",
    "axis = plt.figure(figsize=(5,5)).subplots(1, 1);\n",
    "df_metrics_10percent[\"ACC\"].hist(ax = axis, bins=np.arange(0.85, 0.95, 0.005), grid=False);\n",
    "df_metrics[\"ACC\"].hist(ax=axis,  bins=np.arange(0.85, 0.95, 0.005), fill=False, hatch=\"/\", grid=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaka jest zależność rozrzutu wyniku metryki od rozmiaru próbki?\n",
    "\n",
    "Proszę postawić jakąś hipotezę, a potem uruchomić poniższą komórkę. Czy wykresy zgadzają się z hipotezą?\n",
    "\n",
    "**Uwaga:** wykonanie kodu może zająć kilka minut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def evaluate_std(nEvents, nIter):\n",
    "    metrics_data = calculate_metric(df.sample(nEvents), nIter=nIter) \n",
    "    df_metrics = pd.DataFrame(data=metrics_data, columns = [\"PPV\", \"TPR\", \"ACC\", \"F1\", \"MCC\"])\n",
    "    return df_metrics[\"ACC\"].std()\n",
    "\n",
    "nIter = 100\n",
    "sampleSizes = np.arange(100,10000,500)\n",
    "std_values = [evaluate_std(nEvents, nIter) for nEvents in sampleSizes]\n",
    "\n",
    "plt.plot(sampleSizes, std_values, \".\", label = r\"$\\sigma_{ACC}$\")\n",
    "plt.plot(sampleSizes, std_values*np.sqrt(sampleSizes)/20, \".\", label=r\"$1/20 \\cdot \\sigma_{ACC} \\cdot \\sqrt{n}$\")\n",
    "plt.xlabel(\"Sample size\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gorayUYfqvtc"
   },
   "source": [
    "W czasier analizy wydajności modelu zwykle stosuje się modyfikację losowego podziału na dane treningowe i testowe. Całe dane są dzielone na\n",
    "równych k podziałów (ang. folds) i jest przeprowadzana k-krotna procedura sprawdzania (ang. k-fold cross-validation):\n",
    "\n",
    "0. dzielimy zbiór uczący (features, labels) na `k` równych części\n",
    "1. odkładamy i-tą, i=(0,1,2,3,...,k-1), część jako dane testowe, \n",
    "2. na pozostałych `k-1` częściach uczymy klasyfikator\n",
    "3. obliczamy miary jakości na tej odłożonej części\n",
    "4. wracamy do punktu 1\n",
    "5. na końcu mozna policzyć wartości metryk uśrednione po podziałach\n",
    "\n",
    "Procedura sprawdzania metryk z użyciem \"k-fold cross-validation\" jest zaimplementowana w pakiecie `sklearn` przez funkcję [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html).\n",
    "\n",
    "Funkcja ```print_k_cv_scores(data, model)``` wypisuje na ekran wartości metryk. Funkcja przyjmuje na wejściu:\n",
    "* obiekt DataFrame reprezentujący dane\n",
    "* model z pakietu  `sklearn` reprezentujący model do wytrenowania (w naszym przypadku `LogisticRegression`)\n",
    "\n",
    "Uzupełnij funkcję 'cross_val_score' by wypisywała wartości dla metryk ```['precision','recall','accuracy','f1']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dodajemy metrykę MCC do listy fukncji oceniających\n",
    "metrics.SCORERS['mcc'] = make_scorer(metrics.matthews_corrcoef)\n",
    "\n",
    "def print_k_cv_scores(data, model):\n",
    "    #Lista z nazwami metryk rozpoznawanymi przez funkcję cross_val_score\n",
    "    metric_names = ['precision','recall','accuracy','f1','mcc']\n",
    "    #Pętla po metrykach do policzenia\n",
    "    for metric_name in metric_names:\n",
    "        #Obliczenie wartości metryki\n",
    "        value = cross_val_score(model, data[[\"x\",\"y\"]], data[\"label\"], cv=5, scoring=metric_name)\n",
    "        print(metric_name.capitalize()+' = {0:.2f} +/- {1:.2f}'.format(value.mean(),value.std()))\n",
    "        \n",
    "#Wołamy funkkcję wypisującą wartości metryk        \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OAmVCSKqvti"
   },
   "source": [
    "Metryki pokazują wydajność klasyfikatora dla ustalonego progu klasyfikacji: p>50% -> klasa 1.\n",
    "Zbadajmy jak wyglądają krzywe ROC dla poszczególnych podziałów, oraz dla sumy podziałów. \n",
    "\n",
    "Funkcja ```plot_ROC(data)``` rysuje krzywe ROC dla poszczególnych podziałów, oraz wypisuje dla nich wartości metryk. Funkcja korzysta z obiektu\n",
    "[StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) który zwaraca indeksy elementów należących do zbiorów uczącego i testowego. Funkcja przyjmuje argumenty:\n",
    "* data - obiekt DataFrame zawierający analizowane dane \n",
    "\n",
    "Proszę uzupełnić kod funkcji ```plot_ROC(data)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "def plot_ROC(data, assignAllToClass1 = False):\n",
    "    #Tworzymy obiekt wykonujący podziały próbki\n",
    "    skf  = StratifiedKFold(n_splits=5)\n",
    "    #Definiujemy model który będzie optymalizowany\n",
    "    model = LogisticRegression(solver = 'lbfgs')\n",
    "    #Przygotowujemy pole do rysowania\n",
    "    plt.figure(figsize=(5,5))\n",
    "    #Licznik podziałów\n",
    "    foldNumber=0\n",
    "    #Macierze przechowujące wyniki dla poszczególnych podziałóww\n",
    "    y_pred_sum = np.array([])\n",
    "    y_true_sum = np.array([])\n",
    "\n",
    "    for train_indices, test_indices in skf.split(data, data[\"label\"]):\n",
    "        #Tworzymy zbiory uczący i testowy\n",
    "        df_train = data.reindex(train_indices).dropna()\n",
    "        df_test = data.reindex(test_indices).dropna()\n",
    "        #Wykonujemy dopasowanie do zbioru uczącego\n",
    "        ...\n",
    "        #Wypisujemy wartości metryk dla na zbiorze testowym\n",
    "        print(colored(\"Fold number:\",\"red\"),foldNumber)\n",
    "        ...\n",
    "        #Obliczamy wynik działania modelu (=prawdopodobieństwo przynależności do klas \"0\" i \"1\")\n",
    "        y_pred = model.predict_proba(df_test[[\"x\",\"y\"]])\n",
    "        if assignAllToClass1:\n",
    "            pass \n",
    "        #Wybieramy prawdopodobieństwo przynależności do klasy \"1\"\n",
    "        y_pred = y_pred[:,1] \n",
    "        #Dołączamy wyniki dla danego podziału do macierzy przechowujących dane dla wszyskich podziałów\n",
    "        y_pred_sum = np.append(y_pred_sum, y_pred)\n",
    "        y_true_sum = np.append(y_true_sum, df_test[\"label\"])\n",
    "        #Obliczamy dane dla krzywej ROC\n",
    "        ...\n",
    "        #Obliczamy powierzchnię pod krzywą ROC\n",
    "        ...\n",
    "        #Rysujemy krzywą ROC\n",
    "        plt.plot(fpr, tpr, lw=2, label=\"fold: {:d} (AUC = {:0.3f})\".format(foldNumber, roc_auc))\n",
    "        foldNumber+=1\n",
    "    #Obliczamy i rysujemy krzywą ROC dla sumy podziałów\n",
    "    fpr, tpr, thresholds = roc_curve(y_true_sum, y_pred_sum)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=2, label=\"folds sum (AUC = {:0.3f})\".format(roc_auc))\n",
    "    #Dodajemy krzywą ROC losowego klasyfikatora.\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic for logistic regression')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()   \n",
    "\n",
    "#Wołamy funkcję do rysowania.    \n",
    "plot_ROC(data=df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJ-Nox9uqvtl"
   },
   "source": [
    "Podobnie jak to było w przypadku losowego podziału możemy sprawdzić jak wyniki zależą od rozmiaru zbioru uczącego. Funkcja ```evaluate_metris_with_cross_validation(nEvents, metric_name)``` tworzy obiekt DataFrame zawierający średnią i odchylenie standardowe metryki dla obliczone dla podziałów. Proszę przeanalizować rysunki i odpowiedzieć na pytanie:\n",
    "\n",
    "* która metryka wyróznia się spośród pozostałych?\n",
    "* jak zmienia się odchylenie standardowe metryk względem rozmiaru próbki? Proszę zmodyfikować kod by zweryfikować swoją hipotezę.\n",
    "* jaką wadę ma metryka MCC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def evaluate_metris_with_cross_validation(nEvents, metric_name):\n",
    "    df_train = df.sample(nEvents)\n",
    "    value = cross_val_score(model, df_train[[\"x\",\"y\"]], df_train[\"label\"], cv=5, scoring=metric_name)\n",
    "    return np.array([value.mean(), value.std()])\n",
    "\n",
    "\n",
    "_, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "metric_names = ['precision','recall','accuracy','f1',\"mcc\"]\n",
    "sampleSizes = np.arange(100,5000,500)\n",
    "for metric_index, metric_name in enumerate(metric_names):\n",
    "    scores = np.array([evaluate_cross_validation(nEvents, metric_name) for nEvents in sampleSizes])\n",
    "    axes[0].errorbar(sampleSizes+50*metric_index, scores[:,0], linestyle=\"None\", yerr = scores[:,1], marker=\".\",label = metric_name.capitalize());\n",
    "    axes[1].plot(sampleSizes+50*metric_index, scores[:,1], marker=\".\",label = r\"$\\sigma$ \"+metric_name.capitalize());\n",
    "\n",
    "axes[0].set_xlabel(\"Sample size\")\n",
    "axes[0].legend();\n",
    "\n",
    "axes[1].set_xlabel(\"Sample size\")\n",
    "axes[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analiza dla klas niezrównoważonych.\n",
    "\n",
    "Do tej pory liczebnośc obu klas w analizowanych danych była równa. Korzystając z początkowych zbiorów `class_0_data` oraz `class_1_data` stwórz zbiór w którym klasy nie bedą równoliczne i klasa \"1\" jest 100 razy bardziej liczba niż klasa \"0\".\n",
    "\n",
    "**Wskazówka**: stwórz nowy obiekt DataFrame z danych dkal klas \"0\" i \"1\", ale dobierz próbkowanie danych dkla poszczególnych klas, tak by w sumarycznym zbiorze klasa \"1\" była 100 razy bardziej liczba niż klasa \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_non_equal = ...\n",
    "print(df_non_equal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korzystając z metod klasy DataFrame proszę:\n",
    "* narysować rozkłady wszystkich zmiennych wejściowych oddzielnie dla klas 0 i 1\n",
    "* narysować wykres korelacji między zmiennymi wejściowymi oddzielnie dla klas 0 i 1\n",
    "\n",
    "**Wskazówka**: \n",
    "* proszę użyć filtrowania obiektu DataFrame\n",
    "* proszę użyć parametru \"hue\" funkcji sns.jointplot()\n",
    "\n",
    "Oglądając rysunki proszę sprawdzić jakościowo:\n",
    "* czy krotności klas są zgodne z założeniami?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histogramy rozkładów dla klasy \"0\"\n",
    "...\n",
    "\n",
    "#Histogramy rozkładów dla klasy \"1\"\n",
    "...\n",
    "\n",
    "#Dwuwymiarowy rozkład y vs x dla klasy \"0\" i 1\"\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZL0aq9eBqvtz"
   },
   "source": [
    "Korzystając z funkcji ```plot_ROC(data)``` wypisz na ekran wartości miar, oraz narysuje krzywe ROC dla danych niezrównoważonych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NOKh4VeeqvuD"
   },
   "source": [
    "Powyższe obliczenia obliczenia proszę przeprowadzić dla klas, których rozkłady wyraźnie się różnią i dla takich które się pokrywają w znacznym stopniu. Proszę stworzyć nowe zestawy danych dla przypadków:\n",
    "\n",
    "* kiedy rozkłady (x,y) dla klas \"0\" i \"1\" są bardzo podobne - klasy są trudno rozróznialne\n",
    "\n",
    "I wypisać dla nich wartości metryk oraz narysować krzywe ROC dla niezrównoważonych zbiorów w których klasa \"1\" jest 100 razy bardzije liczba niż klasa \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyższe obliczenia obliczenia proszę przeprowadzić dla klas, których rozkłady wyraźnie się różnią i dla takich które się pokrywają w znacznym stopniu. Proszę stworzyć nowe zestawy danych dla przypadków:\n",
    "\n",
    "* kiedy rozkłady (x,y) dla klas \"0\" i \"1\" są bardzo podobne - klasa są łatwo separowalne\n",
    "\n",
    "I wypisać dla nich wartości metryk oraz narysować krzywe ROC dla niezrównoważonych zbiorów w których klasa \"1\" jest 100 razy bardziej liczba niż klasa \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-fCr9NPqvuE"
   },
   "source": [
    "# Jakie stąd płyną wnioski? \n",
    "\n",
    "1) Jakie płyną konsekwencje z dużej różnicy częstości występowania dwóch klas?\n",
    "\n",
    "2) Które miary jakości są na ten efekt najmniej i najbardziej wrażliwe?\n",
    "\n",
    "3) Jak można przeciwdziałać efektowi częstości występowania?\n",
    "\n",
    "4) Czy efekt częstości występowania ma taki sam czy różny wpływ na miary jakości w przypadku, gdy klasy pochodzą z rozkładów, które się znacząco pokrywają lub są mocno rozseparowane?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "03M_Miary_jakości.ipynb",
   "provenance": [
    {
     "file_id": "16srziWO2XRWYY8AVY9Px_05RQQdYY5jA",
     "timestamp": 1571847683761
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
